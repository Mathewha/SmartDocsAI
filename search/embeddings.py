"""
Embeddings service for semantic search functionality.
Handles text to vector conversion using pre-trained models.
"""

import logging
from typing import List, Optional, Union
import numpy as np

try:
    from sentence_transformers import SentenceTransformer
    SENTENCE_TRANSFORMERS_AVAILABLE = True
except ImportError:
    SENTENCE_TRANSFORMERS_AVAILABLE = False

logger = logging.getLogger(__name__)


class EmbeddingService:
    """Service for generating text embeddings using Sentence Transformers."""
    
    def __init__(self, model_name: str = "all-MiniLM-L6-v2"):
        """
        Initialize the embedding service.
        
        Args:
            model_name: Name of the SentenceTransformer model to use.
                       Default is 'all-MiniLM-L6-v2' which is lightweight and multilingual.
        """
        if not SENTENCE_TRANSFORMERS_AVAILABLE:
            raise ImportError(
                "sentence-transformers is required for semantic search. "
                "Install it with: pip install sentence-transformers"
            )
        
        self.model_name = model_name
        self._model = None
        logger.info(f"Initializing embedding service with model: {model_name}")
    
    @property
    def model(self) -> SentenceTransformer:
        """Lazy loading of the model to avoid loading it on import."""
        if self._model is None:
            logger.info(f"Loading SentenceTransformer model: {self.model_name}")
            self._model = SentenceTransformer(self.model_name)
        return self._model
    
    def get_embedding_dimension(self) -> int:
        """Get the dimension of the embeddings generated by this model."""
        return self.model.get_sentence_embedding_dimension()
    
    def encode_text(self, text: Union[str, List[str]]) -> np.ndarray:
        """
        Convert text(s) to vector embeddings.
        
        Args:
            text: Single text string or list of text strings
            
        Returns:
            numpy array of embeddings (1D for single text, 2D for list)
        """
        if not text or (isinstance(text, str) and not text.strip()):
            # Use fallback text instead of empty to avoid zero vectors
            fallback_text = "empty content"
            logger.warning(f"Empty text input, using fallback: '{fallback_text}'")
            if isinstance(text, list):
                text = [fallback_text] * len(text)
            else:
                text = fallback_text
        
        try:
            # sentence-transformers handles both single strings and lists
            embeddings = self.model.encode(text, convert_to_numpy=True)
            return embeddings.astype(np.float32)
        except Exception as e:
            logger.error(f"Error encoding text: {e}")
            raise
    
    def encode_query(self, query: str) -> List[float]:
        """
        Encode a search query to vector for OpenSearch KNN search.
        
        Args:
            query: Search query string
            
        Returns:
            List of floats representing the query vector
        """
        if not query.strip():
            # Return zero vector for empty query
            return [0.0] * self.get_embedding_dimension()
        
        vector = self.encode_text(query)
        return vector.tolist()
    
    def encode_document_fields(self, 
                             title: Optional[str] = None,
                             content: Optional[str] = None,
                             summary: Optional[str] = None) -> List[float]:
        """
        Encode document fields into a single representative vector.
        
        Args:
            title: Document title
            content: Document content  
            summary: Document summary
            
        Returns:
            List of floats representing the document vector
        """
        # Combine available text fields with appropriate weighting
        text_parts = []
        
        if title and title.strip():
            # Give title more weight by repeating it
            text_parts.extend([title.strip()] * 2)
        
        if summary and summary.strip():
            text_parts.append(summary.strip())
        
        if content and content.strip():
            # For content, take first portion to avoid too much text
            content_excerpt = content[:1000] if len(content) > 1000 else content
            text_parts.append(content_excerpt.strip())
        
        if not text_parts:
            # For empty documents, use a minimal text to avoid zero vectors
            logger.warning("No text content found for document embedding, using default text")
            combined_text = "untitled document"
        else:
            # Combine all text parts
            combined_text = " ".join(text_parts)
        
        logger.debug(f"Encoding document text (length: {len(combined_text)}): {combined_text[:100]}...")
        vector = self.encode_text(combined_text)
        result = vector.tolist()
        
        # Verify we don't have a zero vector (which OpenSearch rejects for cosine similarity)
        if sum(abs(x) for x in result) == 0:
            logger.warning("Generated zero vector, using minimal fallback")
            # Create a minimal non-zero vector
            result = [0.001] * len(result)
        
        return result


# Global instance - will be initialized when first used
_embedding_service: Optional[EmbeddingService] = None


def get_embedding_service() -> EmbeddingService:
    """Get the global embedding service instance."""
    global _embedding_service
    if _embedding_service is None:
        _embedding_service = EmbeddingService()
    return _embedding_service


def encode_query_for_search(query: str) -> List[float]:
    """Convenience function to encode a query for semantic search."""
    service = get_embedding_service()
    return service.encode_query(query)


def encode_document_for_indexing(title: Optional[str] = None,
                               content: Optional[str] = None, 
                               summary: Optional[str] = None) -> List[float]:
    """Convenience function to encode document fields for indexing."""
    service = get_embedding_service()
    return service.encode_document_fields(title, content, summary) 